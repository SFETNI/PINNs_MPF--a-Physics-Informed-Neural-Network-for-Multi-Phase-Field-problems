{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyDOE in /home/selfetni/.local/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy in /home/selfetni/.local/lib/python3.10/site-packages (from pyDOE) (1.24.1)\n",
      "Requirement already satisfied: scipy in /home/selfetni/.local/lib/python3.10/site-packages (from pyDOE) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 21:51:04.384824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-16 21:51:04.862976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "#!/home/selfetni/anaconda3/bin/python3.9.19\n",
    "#print(\"PYTHON VERSION: \",sys.version)\n",
    "# Install pyDOE using pip\n",
    "subprocess.call(['pip', 'install', 'pyDOE'])\n",
    "\n",
    "#!pip install pyDOE\n",
    "\n",
    "\n",
    "import datetime, os\n",
    "#hide tf logs \n",
    "os.environ['TF_CPPclea_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'} \n",
    "#0 (default) shows all, 1 to filter out INFO logs, 2 to additionally filter out WARNING logs, and 3 to additionally filter out ERROR logs\n",
    "import scipy.optimize\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import psutil # memory usage\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "\n",
    "import codecs, json  # save weights\n",
    "import math\n",
    "import glob\n",
    "#from numba import jit\n",
    "# generates same random numbers each time\n",
    "np.random.seed(1234)\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import random\n",
    "import scipy.io as sio\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "import PINN  # python files (classes)\n",
    "import pre_post\n",
    "from pre_post import *\n",
    "from PINN import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_phi_test (40804000, 4)\n",
      "X_f_train: (64000000, 4), X_ini_all: (40804, 4), X_lb_train: (64000, 3), X_ub_train: (64000, 3), X_ltb_train: (64000, 3), X_rtb_train: (64000, 3), phi_ini_all: (40804, 4)\n",
      "\n",
      " ! Initilization of all workers pinns \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "if __name__ == '__main__':     ###################\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################    \n",
    "    #inputs = read_inputs_from_file(\"Input.txt\")\n",
    "\n",
    "    # Grid parameters\n",
    "    Nx=101\n",
    "    Ny=101\n",
    "    Nt=1000  # 500 if los_f\n",
    " \n",
    "    # Define the domain bounds\n",
    "    lb = np.array([0, 0,0])\n",
    "    ub = np.array([1, 1,1]) #np.array([Nx, Ny,Nt])\n",
    "    dx = 1 #(ub[0] - lb[0]) / (Nx - 1)\n",
    "    dy = 1 #(ub[1] - lb[1]) / (Ny - 1)\n",
    "    \n",
    "    # phyisical parameters\n",
    "    sigma= 2\n",
    "    mu= 1e-2\n",
    "    eta=4*dx  # good value 3.5\n",
    "    delta_g= -40\n",
    "\n",
    " \n",
    "    \n",
    "    num_phases=4\n",
    "    loc_index_0 = 0\n",
    "    loc_index_1 = 1\n",
    "    loc_index_2 = 2\n",
    "    loc_index_3 = 3\n",
    "    all_phases_indexes= [loc_index_0, loc_index_1, loc_index_2, loc_index_3]\n",
    "    \n",
    "    N_batches=64      # base of the pyramid\n",
    "    min_batch_numbers =4 # upper surface of the pyramid\n",
    "    # Training batch \n",
    "    Nbr_f_pts_max_per_batch= 1000 #1000\n",
    "    Nbr_f_pts_min_per_batch= 100 #100\n",
    "    N_ini_max_per_batch=25 #50   \n",
    "    N_ini_min_per_batch= 2 #4      \n",
    "    fraction_ones_per_int_pts=0.35\n",
    "    coef_increase_points_f=3 # or decrease\n",
    "    coef_increase_points_ic=1.5 # or decrease\n",
    "\n",
    "    num_train_intervals=Nt\n",
    "    # Define  Collocations, IC and BC points and Domain bounds\n",
    "    N_ini =N_batches *num_train_intervals # Total number of data points for 'phi': IC\n",
    "    N_f = Nbr_f_pts_max_per_batch * N_batches *num_train_intervals    # 100000 Total number of collocation points : domain\n",
    "    N_b=N_batches*Nt   # Total number of data points for boundary BC\n",
    "        \n",
    "    # Total number of data points for 'phi': boundary BC\n",
    "\n",
    "    x = np.unique(np.linspace(lb[0], ub[0], Nx))\n",
    "    y = np.unique(np.linspace(lb[1], ub[1], Ny))\n",
    "    t = np.unique(np.linspace(lb[2], ub[2], Nt))\n",
    "    f_values = [0, 0.33, 0.67, 1]\n",
    "\n",
    "    # Generate all combinations of x, y, t, and f\n",
    "    X, Y, T, F = np.meshgrid(np.linspace(lb[0], ub[0], Nx),\n",
    "                            np.linspace(lb[1], ub[1], Ny),\n",
    "                            np.linspace(lb[2], ub[2], Nt),\n",
    "                            f_values,\n",
    "                            indexing='ij')\n",
    "\n",
    "    # Reshape the arrays to create the test matrix\n",
    "    # = np.column_stack((X.flatten(), Y.flatten(), T.flatten(), F.flatten()))\n",
    "    #np.savez('X_phi_test.npz', X_phi_test=X_phi_test)\n",
    "    \n",
    "    \n",
    "    #X_phi_test = np.load('X_phi_test.npz')['arr_0']\n",
    "    data = np.load('X_phi_test.npz')\n",
    "    X_phi_test= data['X_phi_test']\n",
    "    print(\"X_phi_test\", X_phi_test.shape)\n",
    "    \n",
    "    tb = np.linspace(start=lb[2], stop=ub[2], num=N_b, endpoint=True)\n",
    "    tb = np.expand_dims(tb, axis=1)\n",
    "    \n",
    "    # set the saving paths and erase older results\n",
    "    global pathOutput\n",
    "    pathOutput = os.path.join(os.getcwd(),'save_figs')\n",
    "    if not os.path.isdir(pathOutput):\n",
    "        os.mkdir(pathOutput)\n",
    "    global pathInput\n",
    "    pathInput = os.path.join(os.getcwd(),'Initialization')\n",
    "    if not os.path.isdir(pathInput):\n",
    "        os.mkdir(pathInput)\n",
    "    # to store the weights for each time interval \n",
    "    path_weights= os.path.join(os.getcwd(),'weights')\n",
    "    if not os.path.isdir(path_weights):\n",
    "        os.mkdir(path_weights)\n",
    "\n",
    "    # load PrePost class\n",
    "    reload(pre_post) # for re-execution after modif\n",
    "    from pre_post import *\n",
    "    Pre_Post=PrePost(X=X,T=None, lb=lb, ub=ub, Nx=Nx,Ny=Ny,dx=dx,dy=dy,x=x,y=y, eta=eta,\\\n",
    "                      phi_true=None)\n",
    "\n",
    "    # set the save paths and erase older results\n",
    "    Pre_Post.EraseFile(path=pathOutput)\n",
    "    Pre_Post.EraseFile(path=path_weights)\n",
    "    Pre_Post.EraseFile(path=os.path.join(os.getcwd(),'test_IC'))\n",
    "    #Pre_Post.EraseFile(path=pathInput) # Initialization \n",
    " \n",
    "    # Initialize phases\n",
    "    \n",
    "    phases_indexes,all_flags_matrix, all_phases,\\\n",
    "        all_interfaces=Pre_Post.initialize_phases(all_phases_indexes,pathInput)\n",
    "    \n",
    "    # Save into a dictionary\n",
    "    Initilization_Data = {'phases_indexes': phases_indexes,\\\n",
    "        'all_flags_matrix': all_flags_matrix,\\\n",
    "        'all_phases': all_phases,\\\n",
    "        'all_interfaces': all_interfaces}\n",
    "    #np.savez('Initilization_Data.npz', **Initilization_Data)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load initialization \n",
    "    loaded_data = np.load('Initilization_Data.npz')\n",
    "    phases_indexes = loaded_data['phases_indexes']\n",
    "    all_flags_matrix = loaded_data['all_flags_matrix']\n",
    "    all_phases = loaded_data['all_phases']\n",
    "    all_interfaces = loaded_data['all_interfaces']\n",
    "    \n",
    "    tf.print(\"phases_indexes shape:\", phases_indexes.shape)\n",
    "    tf.print(\"all_flags_matrix shape:\", all_flags_matrix.shape)\n",
    "    tf.print(\"all_phases shape:\", all_phases.shape)\n",
    "    tf.print(\"all_interfaces shape:\", all_interfaces.shape)\n",
    "    \"\"\"\n",
    "    # plot the initial micro\n",
    "    #Pre_Post.plot_init(all_phases,all_phases,Nx,Ny,path=pathOutput)\n",
    "    \n",
    "    # get the training data\n",
    "    X_f_train, X_ini_train_all,X_lb_train,X_ub_train,X_rtb_train,X_ltb_train,phi_ini_all =Pre_Post.set_training_data(x,y,f_values,N_ini,\\\n",
    "        all_phases, all_interfaces,all_flags_matrix,N_f,tb,lb,ub,path=pathOutput)\n",
    "    \n",
    "    # Plot Collocation_IC_BC points\n",
    "    #Pre_Post.plot_Collocation_IC_BC(Nx,Ny,x,y,X_ini_train,X_f_train,X_lb_train,X_ub_train,\\\n",
    "        \n",
    "    # load PINN class\n",
    "    import PINN\n",
    "    reload(PINN)  # mandatory to reload content at each re-call atfer modification\n",
    "    from PINN import *\n",
    "    \n",
    "    ######################################################################## \n",
    "    # Build PINN \n",
    "    layers = np.array([4,128,128,128,128,1])  # Network\n",
    "    PINN_ = Sequentialmodel(layers=layers, X_f_train=X_f_train, X_ini_train=X_ini_train_all,\\\n",
    "                            phases_ini_indexes=phases_indexes,all_ini_flags_matrix=all_flags_matrix,\\\n",
    "                            Phi_ini=all_phases,phi_ini_train=phi_ini_all, N_ini=N_ini,X_phi_test=X_phi_test,\\\n",
    "                            X_ini_train_all=X_ini_train_all, phi_ini_train_all=phi_ini_all,\\\n",
    "                                all_interfaces=all_interfaces,\\\n",
    "                            X_lb_train=X_lb_train, X_ub_train=X_ub_train,\\\n",
    "                            X_ltb_train=X_ltb_train, X_rtb_train=X_rtb_train,\\\n",
    "                            X=X,Y=Y,T=T,x=x,y=y,lb=lb, ub=ub, mu=mu, sigma=sigma, delta_g=delta_g,\\\n",
    "                            eta=eta,Nx=Nx,Ny=Ny,Nt=Nt,phi_sol=None,pinns =None,num_phases=num_phases,\n",
    "                            N_batches=N_batches,\\\n",
    "                            Nbr_f_pts_max_per_batch=Nbr_f_pts_max_per_batch,\\\n",
    "                            Nbr_f_pts_min_per_batch=Nbr_f_pts_min_per_batch,\\\n",
    "                            N_ini_max_per_batch=N_ini_max_per_batch,\\\n",
    "                            N_ini_min_per_batch=N_ini_min_per_batch)\n",
    "    ########################################################################   \n",
    "    # New dir for pinns (the workers) and initialization\n",
    "    path_weights_all_pinns= os.path.join(os.getcwd(),'weights_all_workers_pinns')\n",
    "    if not os.path.isdir(path_weights_all_pinns):\n",
    "        os.mkdir(path_weights_all_pinns)\n",
    "    pinns=PINN_.Initialize_pinns(path_weights_all_pinns)  \n",
    "    ########################################################################      \n",
    "    # transfer learning from already trained model\n",
    "    set_weights_PINN=0\n",
    "    if set_weights_PINN==1:\n",
    "        PINN_.set_weights_Master_PINN()\n",
    "        pinns=PINN_.Initialize_pinns(path_weights_all_pinns) \n",
    "        PINN_.test_IC(N_batches,\"test_IC\")\n",
    "    ########################################################################  \n",
    "    \n",
    "    ########################################################################     \n",
    "    get_initial_weights_pinns=False\n",
    "    restart_simu=0 # raise this flag only if the simulation is restarted (e.g. not finished, no weights are saved)\n",
    "    if get_initial_weights_pinns==True:\n",
    "        path_get_weights_all_pinns= os.path.join(os.getcwd(),'get_weights_all_workers_pinns')\n",
    "        if os.path.exists(path_get_weights_all_pinns) and restart_simu==0:\n",
    "            tf.print(\"!!! removing old 'get_weights_all_workers_pinns' directory !!!\")\n",
    "            time.sleep(5)  # by security \n",
    "            shutil.rmtree(path_get_weights_all_pinns)\n",
    "            shutil.copytree(path_weights_all_pinns, path_get_weights_all_pinns)\n",
    "            \n",
    "        PINN_.set_weights_all_pinns(N_batches,pinns)\n",
    "        PINN_.test_IC(N_batches,\"test_IC\")\n",
    "    Pre_Post.EraseFile(path=path_weights_all_pinns)\n",
    "    ########################################################################      \n",
    "    \n",
    "    # train the Master model\n",
    "    global Nfeval\n",
    "    Nfeval = 1 #(c.f. PINN.py -- scipy optimizer)\n",
    "    start_time = time.time() \n",
    "    ########################################################################  \n",
    "      \n",
    "      \n",
    "      \n",
    "    list_loss= PINN_.train(epochs=1,batch_size_max=1000,thresh= 1e-2,epoch_scipy_opt=21,epoch_print=1,\\\n",
    "                            epoch_resample=1,initial_check=True,save_reg_int=500000,\\\n",
    "                            num_train_intervals=num_train_intervals,\\\n",
    "                            discrete_resolv=True,fraction_ones_per_int_pts=fraction_ones_per_int_pts,\\\n",
    "                                coef_increase_points_f=coef_increase_points_f,\\\n",
    "                                coef_increase_points_ic=coef_increase_points_ic,\\\n",
    "                            path=pathOutput,pinns =pinns,path_weights_all_pinns=path_weights_all_pinns,\\\n",
    "                                save_weights_pinns=True,communicate_pinns=False,\\\n",
    "                                    change_pinn_candidate=False,Thresh_Master=1e-2,optimize_master=False )  \n",
    "\n",
    "    elapsed = time.time() - start_time  \n",
    "    tf.print(\"Training time : \" + (str(datetime.timedelta(seconds=elapsed))) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------\n",
      "  -----  Epoch: 0 <==> N_batches: 64, pinns: 64    -------\n",
      "  ----- time domain:  t_min: 0.00000, t_max: 0.00100\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 03:26:09.630216: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.631495: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.639933: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.646020: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.649468: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.649708: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.652275: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.654505: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.654831: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.655631: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.661034: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.668294: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.670356: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.671371: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.673326: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.673796: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.675120: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.676031: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.676707: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.677058: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.678796: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.679047: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.679461: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.680467: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.680715: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.682009: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.682337: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.683739: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.685348: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.687172: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.687329: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.687485: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n",
      "2023-08-27 03:26:09.687728: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 1 of dimension 1 out of bounds.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2628937/1926739887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m list_loss= PINN_.train(epochs=1,batch_size_max=1000,thresh= 1e-2,epoch_scipy_opt=21,epoch_print=1,\\\n\u001b[0m\u001b[1;32m     10\u001b[0m                         \u001b[0mepoch_resample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_reg_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0mnum_train_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_intervals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Simulations/PINN/Triple_Junction/triple_junction_2D_V37_3/PINN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size_max, thresh, epoch_scipy_opt, epoch_print, epoch_resample, initial_check, save_reg_int, num_train_intervals, discrete_resolv, fraction_ones_per_int_pts, coef_increase_points_f, coef_increase_points_ic, path, pinns, path_weights_all_pinns, save_weights_pinns, communicate_pinns, change_pinn_candidate, Thresh_Master, optimize_master)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                                 \u001b[0mmax_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m                                 \u001b[0mmax_loss_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_batch\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpinns_adam_below_thresh\u001b[0m \u001b[0;32mand\u001b[0m  \u001b[0mpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         '''\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Simulations/PINN/Triple_Junction/triple_junction_2D_V37_3/PINN.py\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(self, batch_X_f, batch_X_ini, batch_X_lb, batch_X_ub, batch_X_ltb, batch_X_rtb, batch_phi_ini, model)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mt_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;31m# Make copy from self for testing and saving actual results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         PINN_ = Sequentialmodel(layers=self.layers, X_f_train=self.X_f, X_ini_train=self.X_ini,\\\n",
      "\u001b[0;32m~/Simulations/PINN/Triple_Junction/triple_junction_2D_V37_3/PINN.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, xf, x_ini, x_lb, x_ub, x_ltb, x_rtb, phi_ini, abs_x_min, abs_x_max, abs_y_min, abs_y_max)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mgrads_w_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flatten weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mgrads_b_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flatten biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mgrads_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrads_1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_w_1d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#concat grad_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Simulations/PINN/Triple_Junction/triple_junction_2D_V37_3/PINN.py\u001b[0m in \u001b[0;36mloss_IC\u001b[0;34m(self, x_ini, phi_ini)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ltb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_rtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" !!! !!! !!! !!! :\\n !!! increase your BC points !!!:\\n !!! !!! !!! !!! :\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mflag_lb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6656\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # train the Master model\n",
    "    global Nfeval\n",
    "    Nfeval = 1 #(c.f. PINN.py -- scipy optimizer)\n",
    "    start_time = time.time() \n",
    "    ########################################################################  \n",
    "      \n",
    "      \n",
    "      \n",
    "    list_loss= PINN_.train(epochs=1,batch_size_max=1000,thresh= 1e-2,epoch_scipy_opt=21,epoch_print=1,\\\n",
    "                            epoch_resample=1,initial_check=True,save_reg_int=500000,\\\n",
    "                            num_train_intervals=num_train_intervals,\\\n",
    "                            discrete_resolv=True,fraction_ones_per_int_pts=fraction_ones_per_int_pts,\\\n",
    "                                coef_increase_points_f=coef_increase_points_f,\\\n",
    "                                coef_increase_points_ic=coef_increase_points_ic,\\\n",
    "                            path=pathOutput,pinns =pinns,path_weights_all_pinns=path_weights_all_pinns,\\\n",
    "                                save_weights_pinns=True,communicate_pinns=False,\\\n",
    "                                    change_pinn_candidate=False,Thresh_Master=1e-2,optimize_master=False )  \n",
    "\n",
    "    elapsed = time.time() - start_time  \n",
    "    tf.print(\"Training time : \" + (str(datetime.timedelta(seconds=elapsed))) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !!!  saving weights of pinns in progress !!! \n",
      "\n",
      "\n",
      "      ! saving complete ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "PINN_.save_weights_for_pinns(N_batches, path_weights_all_pinns, PINN_.t_min, PINN_.t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repository_files_discret_workers(PINN,N_batches,pathOutput,path_weights_all_pinns):\n",
    "\n",
    "\n",
    "\n",
    "    # Make copy from self for testing and saving actual results        \n",
    "    PINN_ = Sequentialmodel(layers=PINN.layers, X_f_train=PINN.X_f, X_ini_train=PINN.X_ini,\\\n",
    "                            phases_ini_indexes=PINN.phases_ini_indexes,all_ini_flags_matrix=PINN.All_flag_ini,\\\n",
    "                            Phi_ini=PINN.All_phi_ini,phi_ini_train=PINN.phi_ini, N_ini=PINN.N_ini,X_phi_test=PINN.X_phi_test,\\\n",
    "                            X_ini_train_all=PINN.X_ini_train_all, phi_ini_train_all=PINN.phi_ini_train_all,\\\n",
    "                                all_interfaces=PINN.All_interfaces_ini,\\\n",
    "                            X_lb_train=PINN.X_lb, X_ub_train=PINN.X_rtb,\\\n",
    "                            X_ltb_train=PINN.X_ltb, X_rtb_train=PINN.X_rtb,\\\n",
    "                            X=None,Y=None,T=None,x=PINN.x,y=PINN.y,lb=PINN.lb, ub=PINN.ub, mu=PINN.mu, sigma=PINN.sigma, delta_g=PINN.delta_g,\\\n",
    "                                eta=PINN.eta,Nx=PINN.Nx,Ny=PINN.Ny,Nt=PINN.Nt,phi_sol=None,pinns =PINN.pinns,num_phases=PINN.num_phases)       \n",
    "    \n",
    "    for phase_idx in range(PINN.num_phases):\n",
    "        n=len(X_ini_train_all)\n",
    "        N=PINN.num_phases\n",
    "        X_phi_test= PINN_.X_ini_train_all[int(n*phase_idx/N)+1:int(n*(phase_idx+1)/N)]\n",
    "        phi_test= PINN_.phi_ini_train_all[int(n*phase_idx/N)+1:int(n*(phase_idx+1)/N)]\n",
    "        #plt.scatter(X_phi_test[:, 0], X_phi_test[:, 1], cmap=plt.get_cmap('viridis'), c=np.sum(phi_test, axis=1, keepdims=True),alpha=0.8)\n",
    "        #plt.colorbar( shrink=0.35)\n",
    "        #plt.show()\n",
    "        \n",
    "        phi_evolution_t_min = []\n",
    "        phi_evolution_t_max = []\n",
    "        X_phi_test_subsets = []\n",
    "        # Predict \n",
    "        for i in range(N_batches):\n",
    "            pinn=PINN.pinns[i]\n",
    "            \n",
    "            t_min, t_max = PINN.t_min, PINN.t_max # self.PRE_POST.extract_t_min_t_max(weights_file)\n",
    "            x_min, x_max, y_min, y_max=pinn.limits\n",
    "            \"\"\"\n",
    "            X_phi_test_sub = PINN_.X_phi_test[:, 2] >= t_min\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 2] <= t_max\n",
    "            #tf.print(\"here in save : \",x_min, x_max, y_min, y_max)\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 0] >= x_min\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 0] <= x_max\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 1] >= y_min\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 1] <= y_max   \n",
    "            X_phi_test_sub = PINN_.X_phi_test[X_phi_test_sub] \n",
    "\n",
    "            X_phi_test_sub[:, 2] = t_min\n",
    "            \"\"\"           \n",
    "            indices = np.where(\n",
    "                (X_phi_test[:, 0] >= x_min) &\n",
    "                (X_phi_test[:, 0] <= x_max) &\n",
    "                (X_phi_test[:, 1] >= y_min) &\n",
    "                (X_phi_test[:, 1] <= y_max)\n",
    "            )\n",
    "            \n",
    "            X_phi_test_sub = X_phi_test[indices] \n",
    "            phi_test_sub = phi_test[indices][:, phase_idx]  \n",
    "                        \n",
    "            phi_pred_t_min  = pinn.evaluate(X_phi_test_sub)[:, phase_idx]\n",
    "            \n",
    "            #phi_evolution_t_min.append(phi_pred_t_min )\n",
    "\n",
    "            #X_phi_test_sub[:, 2] = t_max\n",
    "            #X_phi_test_subsets.append(X_phi_test_sub)\n",
    "            #phi_pred_t_max = pinn.evaluate(X_phi_test_sub).numpy()\n",
    "            #phi_pred_t_max  = phi_pred_t_max[:, phase_idx]\n",
    "        \n",
    "            #phi_evolution_t_max.append(phi_pred_t_max )\n",
    "            \n",
    "            phi=phi_pred_t_min\n",
    "            plt.scatter(X_phi_test_sub[:, 0], X_phi_test_sub[:, 1], cmap=plt.get_cmap('viridis'), c=phi,vmin=0,vmax=1)\n",
    "            x_avg = (x_min + x_max) / 2\n",
    "            y_avg = (y_min + y_max) / 2\n",
    "\n",
    "            plt.text(x_avg, y_avg, f\"{i}\", color='black', ha='right', va='bottom')\n",
    "            \n",
    "            #plt.show()\n",
    "            #plt.xlim([x_min, x_max])\n",
    "            #plt.ylim([y_min, y_max])\n",
    "        plt.colorbar()\n",
    "        #plt.tight_layout()\n",
    "        fig_name = f\"Workers_Pred_Phase_{phase_idx}_at_time_interval_tmin_{t_min:.5f}_tmax_{t_max:.5f}.png\"\n",
    "        plt.savefig(os.path.join(pathOutput ,fig_name)) \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_repository_files_discret_workers(PINN_,N_batches,\"test_rep\",path_weights_all_pinns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_average_weights_and_save(PINN_, weights_key=0):\n",
    "    t_min=PINN_.t_min\n",
    "    t_max=PINN_.t_max\n",
    "    \n",
    "    weights_list = []\n",
    "    for pinn in PINN_.pinns:\n",
    "        weights_list.append(pinn.get_weights())\n",
    "    # compute the average of the weights and biases\n",
    "    average_weights = weights_list[-1]#sum(weights_list) / len(weights_list)\n",
    "    #tf.print(\"Heeere:\",np.asarray(average_weights).shape, len(weights_list) )\n",
    "    PINN_.set_weights(average_weights)\n",
    "    weights_file = 'weights/weights_tmin_{:.5f}_tmax_{:.5f}_{}.json'.format(t_min, t_max, weights_key)\n",
    "    PINN_.save_weights(PINN_,weights_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_average_weights_and_save(PINN_, weights_key=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repository_files_discret_Master(PINN_,path,pathOutput):\n",
    "        weights_files = PINN_.PRE_POST.read_weights_files(path)\n",
    "        print(weights_files)\n",
    "\n",
    "        X_ini_train_all=PINN_.X_ini_train_all\n",
    "    \n",
    "        phase_idx = 0#random.randint(0, PINN_.num_phases - 1)\n",
    "\n",
    "\n",
    "        n=len(X_ini_train_all)\n",
    "        N=PINN_.num_phases\n",
    "        X_phi_test= PINN_.X_ini_train_all[int(n*phase_idx/N)+1:int(n*(phase_idx+1)/N)]\n",
    "        phi_test= PINN_.phi_ini_train_all[int(n*phase_idx/N)+1:int(n*(phase_idx+1)/N)]\n",
    "        \n",
    "        phi_evolution = []\n",
    "        for weights_file in weights_files:\n",
    "            t_min, t_max = PINN_.PRE_POST.extract_t_min_t_max(weights_file)\n",
    "            #tf.print(\"t_min, t_max: \",t_min, t_max)\n",
    "            weights_loaded = PINN_.PRE_POST.load_weights(weights_file)\n",
    "            PINN_.set_weights(weights_loaded)\n",
    "            \"\"\"\n",
    "            X_phi_test_sub = PINN_.X_phi_test[:, 2] >= t_min\n",
    "            X_phi_test_sub &= PINN_.X_phi_test[:, 2] <= t_max\n",
    "            X_phi_test_sub = PINN_.X_phi_test[X_phi_test_sub, :]           \n",
    "            X_phi_test_sub[:, 2] = t_min\n",
    "            \n",
    "            phi_pred = PINN_.evaluate(X_phi_test_sub).numpy()[:, phase_idx]\n",
    "            phi_evolution.append(phi_pred)\n",
    "            \"\"\"\n",
    "        # last one \n",
    "        X_phi_test[:, 2] = t_max\n",
    "        phi_pred = PINN_.evaluate(X_phi_test).numpy()[:, phase_idx]\n",
    "        phi_evolution.append(phi_pred)  \n",
    "        num_boxes = 4     \n",
    "        filename = \"save_preditions\" + \"_phase_{}\".format(str(phase_idx))+\".jpg\"\n",
    "        #tf.print(\"filename\",filename)\n",
    "        PINN_.PRE_POST.plot_global_evolution_discret(num_boxes,X_phi_test,phi_evolution, pathOutput,\"title\", filename,t_max,PINN_.Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/selfetni/Simulations/PINN/Triple_Junction/triple_junction_2D_V3/weights/weights_tmin_0.00000_tmax_0.01000_0.json']\n"
     ]
    }
   ],
   "source": [
    "process_repository_files_discret_Master(PINN_,path_weights,\"test_rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square Matrix:\n",
      "[[0.1 0.2 0.8 1. ]\n",
      " [0.5 1.  0.3 0.7]\n",
      " [0.6 1.  0.4 0.2]\n",
      " [0.3 0.2 0.1 0.5]]\n",
      "[0.1 0.2 0.8 1.  0.5 1.  0.3 0.7 0.6 1.  0.4 0.2 0.3 0.2 0.1 0.5]\n",
      "\n",
      "Phi_0 (Multiplied by 4):\n",
      "[[0.4 0.8 3.2 4. ]\n",
      " [2.  4.  1.2 2.8]\n",
      " [2.4 4.  1.6 0.8]\n",
      " [1.2 0.8 0.4 2. ]]\n",
      "\n",
      "Interface Indices:\n",
      "(array([3, 5, 9]),)\n"
     ]
    }
   ],
   "source": [
    "# Generate a square matrix of size 4x4\n",
    "square_matrix = np.array([\n",
    "    [0.1, 0.2, 0.8, 1.0],\n",
    "    [0.5, 1.0, 0.3, 0.7],\n",
    "    [0.6, 1.0, 0.4, 0.2],\n",
    "    [0.3, 0.2, 0.1, 0.5]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Find the indices where 0.9 < Phi_0 <= 1\n",
    "interface_indices = np.where(np.logical_and(square_matrix.flatten() > 0.9, square_matrix.flatten() <= 1))\n",
    "\n",
    "print(\"Square Matrix:\")\n",
    "print(square_matrix)\n",
    "print(square_matrix.flatten())\n",
    "\n",
    "\n",
    "print(\"\\nPhi_0 (Multiplied by 4):\")\n",
    "print(Phi_0)\n",
    "print(\"\\nInterface Indices:\")\n",
    "print(interface_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_matrix.flatten()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:17:57.221634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-02 17:17:57.452722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:17:57.452737: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-02 17:18:00.242015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:18:00.242066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-02 17:18:00.242071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3593063/219084231.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is not available or not visible to TensorFlow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:18:04.587923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-02 17:18:04.594930: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-08-02 17:18:04.594949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: WS8692.zit.bam.de\n",
      "2023-08-02 17:18:04.594953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: WS8692.zit.bam.de\n",
      "2023-08-02 17:18:04.595059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.125.6\n",
      "2023-08-02 17:18:04.595073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.105.1\n",
      "2023-08-02 17:18:04.595076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 515.105.1 does not match DSO version 525.125.6 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available and visible to TensorFlow\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and visible to TensorFlow.\")\n",
    "else:\n",
    "    print(\"GPU is not available or not visible to TensorFlow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if TensorFlow-GPU is installed\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_intersection(square1, square2):\n",
    "    x_min1, x_max1,y_min1, y_max1 = square1\n",
    "    x_min2, x_max2, y_min2, y_max2 = square2\n",
    "    x_avg_1 = (x_min1 + x_max1) / 2\n",
    "    y_avg_1 = (y_min1 + y_max1) / 2\n",
    "    x_avg_2 = (x_min2 + x_max2) / 2\n",
    "    y_avg_2 = (y_min2 + y_max2) / 2\n",
    "    dist_centers=np.sqrt((x_avg_1-x_avg_2)**2 +(y_avg_1-y_avg_2)**2)\n",
    "    a_1=np.abs((x_min1- x_max1))\n",
    "    b_1=np.abs((y_min1- y_max1))\n",
    "    a_2=np.abs((x_min2- x_max2))\n",
    "    b_2=np.abs((y_min2-y_max2))\n",
    "    r1=a_1/2\n",
    "    r2=a_2/2\n",
    "\n",
    "    return  (dist_centers < (r1+r2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "square1 = [0,10,10,20]\n",
    "square2 = [5,10,10,15]\n",
    "print(is_intersection(square1, square2))\n",
    "# Extracting coordinates for each square\n",
    "x_min1, y_min1, x_max1, y_max1 = square1[0], square1[2], square1[1] , square1[3]\n",
    "x_min2, y_min2, x_max2, y_max2 = square2[0], square2[2], square2[1] , square2[3]\n",
    "x_avg_1 = (x_min1 + x_max1) / 2\n",
    "y_avg_1 = (y_min1 + y_max1) / 2\n",
    "x_avg_2 = (x_min2 + x_max2) / 2\n",
    "y_avg_2 = (y_min2 + y_max2) / 2\n",
    "a_1=np.abs((x_min1- x_max1))\n",
    "b_1=np.abs((y_min1- y_max1))\n",
    "a_2=np.abs((x_min2- x_max2))\n",
    "b_2=np.abs((y_min2-y_max2))\n",
    "r1=a_1/2\n",
    "r2=a_2/2\n",
    "# Creating subplots\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# Plotting the first square\n",
    "rect1 = plt.Rectangle((x_min1, y_min1), x_max1 - x_min1, y_max1 - y_min1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect1)\n",
    "circle_1=plt.Circle((x_avg_1, y_avg_1), r1, color='r', fill=False)\n",
    "ax.add_artist(circle_1)\n",
    "# Plotting the second square\n",
    "rect2 = plt.Rectangle((x_min2, y_min2), x_max2 - x_min2, y_max2 - y_min2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "ax.add_patch(rect2)\n",
    "circle_2=plt.Circle((x_avg_2, y_avg_2), r2, color='b', fill=False)\n",
    "ax.add_artist(circle_2)\n",
    "# Set axis limits\n",
    "plt.xlim(0, max(x_max1, x_max2) + 2)\n",
    "plt.ylim(0, max(y_max1, y_max2) + 2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Plot of Squares')\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829493/329937679.py:38: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def draw_colored_box_boundaries(ax, rows, cols, color, linestyle='-'):\n",
    "    box_width = 1.0 / cols\n",
    "    box_height = 1.0 / rows\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = col * box_width\n",
    "            y = row * box_height\n",
    "            if x==0 and y==0:\n",
    "                fill=False\n",
    "                ax.add_patch(plt.Rectangle((x, y), box_width, box_height, fill=fill, color=color, linestyle=linestyle))\n",
    "            else:\n",
    "                fill=False\n",
    "                ax.add_patch(plt.Rectangle((x, y), box_width, box_height, fill=fill, color=color, linestyle=linestyle))\n",
    "            box_num = row * cols + col\n",
    "            ax.text(x + box_width / 2, y + box_height / 2, str(box_num), va='center', ha='center', color=color)\n",
    "            #plt.text(0.5, 0.5, r\"$\\bf{IC\\ points\\ well\\ filled}$\", color=\"orange\", fontsize=16, ha=\"center\", va=\"center\")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "\n",
    "colors = ['red', 'green', 'purple', 'orange', 'cyan']\n",
    "line_styles = ['-', '--', ':', '-.', '-']\n",
    "#draw_colored_box_boundaries(ax, rows=10, cols=10, color='red', linestyle='-')\n",
    "#draw_colored_box_boundaries(ax, rows=8, cols=8, color='orange', linestyle='--')\n",
    "draw_colored_box_boundaries(ax, rows=6, cols=6, color='green', linestyle='-')\n",
    "draw_colored_box_boundaries(ax, rows=4, cols=4, color='blue', linestyle='-.')\n",
    "#draw_colored_box_boundaries(ax, rows=1, cols=1, color='blue', linestyle='-.')\n",
    "\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "#plt.gca().invert_xaxis()\n",
    "#plt.gca().invert_yaxis()\n",
    "#plt.gca().set_aspect('equal', adjustable='box')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_colored_box_boundaries(ax, x_range, y_range, z_level, color, linestyle='-', rows=10, cols=10):\n",
    "    box_width = (x_range[1] - x_range[0]) / cols\n",
    "    box_height = (y_range[1] - y_range[0]) / rows\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for row in range(rows + 1):\n",
    "        y = y_range[0] + row * box_height\n",
    "        lines.append([(x_range[0], y, z_level), (x_range[1], y, z_level)])\n",
    "\n",
    "    for col in range(cols + 1):\n",
    "        x = x_range[0] + col * box_width\n",
    "        lines.append([(x, y_range[0], z_level), (x, y_range[1], z_level)])\n",
    "\n",
    "    line_collection = Line3DCollection(lines, color=color, linestyle=linestyle)\n",
    "    ax.add_collection3d(line_collection)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x = x_range[0] + col * box_width\n",
    "            y = y_range[0] + row * box_height\n",
    "            box_num = row * cols + col\n",
    "            ax.text(x + box_width / 2, y + box_height / 2, z_level, str(box_num), va='center', ha='center', color=color)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = ['red', 'green', 'blue', 'orange']\n",
    "line_styles = ['-', '--', ':', '-.']\n",
    "\n",
    "n_col_start = n_row_start = 16\n",
    "n_col_end = n_row_end = 2\n",
    "\n",
    "num_subdivisions = 8\n",
    "z_levels = list(range(num_subdivisions))\n",
    "x_ranges = [(i / n_col_start, 1 - i / n_col_start) for i in z_levels]\n",
    "y_ranges = [(i / n_col_start, 1 - i / n_col_start) for i in z_levels]\n",
    "x_ranges\n",
    "\n",
    "for i, (z_level, x_range, y_range) in enumerate(zip(z_levels, x_ranges, y_ranges)):\n",
    "    linestyle = line_styles[i % len(line_styles)]\n",
    "    color = np.random.rand(3) \n",
    "    draw_colored_box_boundaries(ax, x_range=x_range, y_range=y_range, z_level=z_level, color=color, linestyle=linestyle, rows=n_col_start, cols=n_row_start)\n",
    "    n_col_start -= 2\n",
    "    n_row_start -= 2\n",
    "\n",
    "ax.set_zlim(0, max(z_levels) + 1)\n",
    "ax.grid(False)  \n",
    "\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Level\")\n",
    "ax.set_title(\"3D Grid of Colored Box Boundaries with Subdivisions and Numbering\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your code)\n",
    "\n",
    "# Set the backend to 'TkAgg'\n",
    "plt.switch_backend('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(500 *1.05**3) /int(500 *1.05**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 262 2\n",
      "551 275 3\n"
     ]
    }
   ],
   "source": [
    "alpha=1\n",
    "Nbr_f_pts_max_per_batch= 500 # 5000\n",
    "Nbr_f_pts_min_per_batch= 250\n",
    "for _ in range(2):\n",
    "    alpha+=1     \n",
    "    Nbr_f_pts_max_per_batch=int(1.05*Nbr_f_pts_max_per_batch)  \n",
    "    Nbr_f_pts_min_per_batch=int(1.05*Nbr_f_pts_min_per_batch)  \n",
    "    print(Nbr_f_pts_max_per_batch,Nbr_f_pts_min_per_batch,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 249 3\n"
     ]
    }
   ],
   "source": [
    "Nbr_f_pts_max_per_batch = int(Nbr_f_pts_max_per_batch / (1.05 ** (alpha-1)))  # revert the increase\n",
    "Nbr_f_pts_min_per_batch = int(Nbr_f_pts_min_per_batch / (1.05 ** (alpha-1)))  # revert the increase\n",
    "print(Nbr_f_pts_max_per_batch,Nbr_f_pts_min_per_batch,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi TensorShape([10, 2])\n",
      "x.shape TensorShape([10, 2])\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1321030/4175107678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"phi_x.shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Generate sample data\n",
    "num_samples = 10\n",
    "num_features = 2\n",
    "phi = np.random.rand(num_samples, num_features)\n",
    "x = np.random.rand(num_samples, num_features)\n",
    "phi = tf.constant(phi, dtype='float64')\n",
    "x = tf.constant(x, dtype='float64')\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tf.print(\"phi\", phi.shape)\n",
    "    \n",
    "    tf.print(\"x.shape\", x.shape)\n",
    "\n",
    "    phi_x = tape.gradient(phi, x)\n",
    "\n",
    "        \n",
    "    tf.print(\"phi_x.shape\", phi_x.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "phi = tf.constant([[0.57216301331866315],\n",
    "                   [0.58973358583815072],\n",
    "                   [0.57216301331866315],\n",
    "                   [0.51324975953493235],\n",
    "                   [0.58973358583815072]], dtype=tf.float64)\n",
    "\n",
    "x = tf.constant([[0.84845350302273703],\n",
    "                 [0.83831411733031425],\n",
    "                 [0.82712762154129194],\n",
    "                 [0.89464855159043699],\n",
    "                 [0.82712762154129194]], dtype=tf.float64)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(phi)\n",
    "    tape.watch(x)  \n",
    "    phi_x = tape.gradient(phi, x)\n",
    "print(phi_x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function pfor.<locals>.f at 0x7f0180638790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('fallback_to_while_loop', 'iters', 'loop_fn', 'parallel_iterations', 'warn'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function pfor.<locals>.f at 0x7f0180638790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('fallback_to_while_loop', 'iters', 'loop_fn', 'parallel_iterations', 'warn'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f0180638790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float64, numpy=\n",
       "array([[[2., 0.],\n",
       "        [0., 4.]],\n",
       "\n",
       "       [[6., 0.],\n",
       "        [0., 8.]]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as g:\n",
    "  x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float64)\n",
    "  g.watch(x)\n",
    "  y = x * x\n",
    "  print(x.shape)\n",
    "  print(y.shape)\n",
    "batch_jacobian = g.batch_jacobian(y, x)\n",
    "batch_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "phi = tf.constant([0.57216301331866315,\n",
    "                   0.58973358583815072,\n",
    "                   0.57216301331866315,\n",
    "                   0.51324975953493235,\n",
    "                   0.58973358583815072], dtype=tf.float64)\n",
    "\n",
    "x=tf.constant([[1., 2.], [3., 4.]], dtype=tf.float64)\n",
    "\n",
    "with tf.GradientTape(\n",
    "      watch_accessed_variables=False, persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "dy_dx = tape.gradient(x*x, x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(5,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "x = tf.constant([0.57216301331866315,\n",
    "                   0.58973358583815072,\n",
    "                   0.57216301331866315,\n",
    "                   0.51324975953493235,\n",
    "                   0.58973358583815072], dtype=tf.float64)\n",
    "phi = tf.constant([0.81845350302273703,\n",
    "                 0.82831411733031425,\n",
    "                 0.83712762154129194,\n",
    "                 0.89464855159043699,\n",
    "                 0.99712762154129194], dtype=tf.float64)\n",
    "print(x.shape)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  tape.watch(phi)\n",
    "  print(phi.shape)\n",
    "\n",
    "\n",
    "  print(tape.gradient(phi, x))  \n",
    "  del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (5,) must have rank at least 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1406761/3079712658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Watch the 'v' tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgradient_u_with_respect_to_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_jacobian\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mbatch_jacobian\u001b[0;34m(self, target, source, unconnected_gradients, parallel_iterations, experimental_use_pfor)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m     if not (target_shape.with_rank_at_least(2) and\n\u001b[0m\u001b[1;32m   1271\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             dim.is_compatible_with(source.shape[0])):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[1;32m   1140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (5,) must have rank at least 2"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example vectors\n",
    "u = tf.constant([0.7, 0.5, 0.2, 0.9, 0.3], dtype=tf.float32)\n",
    "v = tf.constant([1.2, 2.5, 0.8, 0.4, 3.0], dtype=tf.float32)\n",
    "\n",
    "# Compute the gradient using tf.GradientTape\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(v)  # Watch the 'v' tensor\n",
    "\n",
    "gradient_u_with_respect_to_v = tape.batch_jacobian (u, v)\n",
    "\n",
    "print(\"u:\", u)\n",
    "print(\"v:\", v)\n",
    "print(\"Gradient of 'u' with respect to 'v':\", gradient_u_with_respect_to_v)\n",
    "\n",
    "# Clean up the resources used by the tape\n",
    "del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3646211723.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1747073/3646211723.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    0.58973358583815072](, dtype=tf.float64)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "phi = tf.constant[0.57216301331866315,\n",
    "                   0.58973358583815072,\n",
    "                   0.57216301331866315,\n",
    "                   0.51324975953493235,\n",
    "                   0.58973358583815072](, dtype=tf.float64)\n",
    "\n",
    "x = tf.constant([0.81845350302273703,\n",
    "                 0.82831411733031425,\n",
    "                 0.83712762154129194,\n",
    "                 0.89464855159043699,\n",
    "                 0.99712762154129194], dtype=tf.float64)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(phi)\n",
    "    tape.watch(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    grad_phi_x = tape.gradient(phi, x)\n",
    "    print(grad_phi_x)\n",
    "    del tape\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1) (6, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'batch_jacobian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_phi\u001b[39m(x):\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m  \u001b[39m# Replace with your actual phi computation\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m batch_jacobian_phi_x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mbatch_jacobian(compute_phi, x)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBatch Jacobian of phi with respect to x:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, batch_jacobian_phi_x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'batch_jacobian'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch: 0, total_loss: 5.391e-04, loss_BC: 0.000e+00, loss_IC: 3.485e-04, loss_f: 1.907e-04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1) (4, 1)\n",
      "tf.Tensor(\n",
      "[[0.2       ]\n",
      " [0.40000001]\n",
      " [0.60000002]\n",
      " [0.80000001]], shape=(4, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y = tf.cast([0.2,\n",
    "                   0.4,\n",
    "                   0.6,\n",
    "                   0.8], dtype=tf.float64)\n",
    "\n",
    "x = tf.cast([0.1,\n",
    "                 0.2,\n",
    "                 0.3,\n",
    "                 0.4], dtype=tf.float64)\n",
    "\n",
    "x = tf.reshape(x, (-1, 1))\n",
    "y = tf.reshape(y, (-1, 1))\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    tape.watch(x)\n",
    "    z=y*(x)\n",
    "    tape.watch(z)\n",
    "    grad_y_x = tape.gradient(z,x)\n",
    "    print(grad_y_x)\n",
    "del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(4, 0), dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.diff(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/selfetni/anaconda3/lib/python3.9/site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Using cached pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-23.2.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.autodiff' has no attribute 'batch_jacobian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1406761/850277236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Compute the batch Jacobian using tf.autodiff.batch_jacobian()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mjacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautodiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.autodiff' has no attribute 'batch_jacobian'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example vectors\n",
    "u = tf.constant([[0.7], [0.5], [0.2], [0.9], [0.3]], dtype=tf.float32)\n",
    "v = tf.constant([[1.2], [2.5], [0.8], [0.4], [3.0]], dtype=tf.float32)\n",
    "\n",
    "# Define a function that computes u using v\n",
    "def compute_u(v):\n",
    "    return v ** 2\n",
    "\n",
    "# Compute the batch Jacobian using tf.autodiff.batch_jacobian()\n",
    "jacobian = tf.autodiff.batch_jacobian(compute_u, v)\n",
    "\n",
    "print(\"u:\\n\", u)\n",
    "print(\"v:\\n\", v)\n",
    "print(\"Batch Jacobian of 'u' with respect to 'v':\\n\", jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]], shape=(5, 1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "phi = tf.constant([[0.7],\n",
    "                   [0.5],\n",
    "                   [0.2],\n",
    "                   [0.9],\n",
    "                   [0.3]], dtype=tf.float64)\n",
    "\n",
    "x = tf.constant([[1.2],\n",
    "                 [2.5],\n",
    "                 [0.8],\n",
    "                 [0.4],\n",
    "                 [3.0]], dtype=tf.float64)\n",
    "\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(phi)\n",
    "    tape.watch(x)\n",
    "\n",
    "\n",
    "grad_phi_x = tape.batch_jacobian(2*x, x)\n",
    "print(grad_phi_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pinns_below_avg=[1,2,3]\n",
    "idx_pinn=0\n",
    "target_idx_values = [target_idx for target_idx in pinns_below_avg]\n",
    "differences = [abs(idx_pinn - idx) for idx in target_idx_values]\n",
    "nearest_index = differences.index(min(differences))\n",
    "print(nearest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pinns_below_avg = [1, 2, 3]\n",
    "idx_pinn = 0\n",
    "differences = [abs(idx_pinn - idx) for idx in pinns_below_avg]\n",
    "nearest_element = pinns_below_avg[differences.index(min(differences))]\n",
    "print(nearest_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_batches = 16\n",
    "matrix_size = int(np.sqrt(N_batches))\n",
    "\n",
    "# Create a square matrix containing indices\n",
    "matrix = np.arange(N_batches).reshape(matrix_size, matrix_size)\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter 1 Indices:\n",
      "[ 0  1  2  6  7  8 12 13 14]\n",
      "\n",
      "Quarter 2 Indices:\n",
      "[ 3  4  5  9 10 11 15 16 17]\n",
      "\n",
      "Quarter 3 Indices:\n",
      "[18 19 20 24 25 26 30 31 32]\n",
      "\n",
      "Quarter 4 Indices:\n",
      "[21 22 23 27 28 29 33 34 35]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_batches = 36\n",
    "matrix_size = int(np.sqrt(N_batches))\n",
    "\n",
    "# Create a square matrix containing indices\n",
    "matrix = np.arange(N_batches).reshape(matrix_size, matrix_size)\n",
    "\n",
    "# Divide the matrix into four quarters\n",
    "quarter1 = matrix[:matrix_size//2, :matrix_size//2]\n",
    "quarter2 = matrix[:matrix_size//2, matrix_size//2:]\n",
    "quarter3 = matrix[matrix_size//2:, :matrix_size//2]\n",
    "quarter4 = matrix[matrix_size//2:, matrix_size//2:]\n",
    "\n",
    "# Print the indices of each quarter as single lists\n",
    "print(\"Quarter 1 Indices:\")\n",
    "print(quarter1.flatten())\n",
    "\n",
    "print(\"\\nQuarter 2 Indices:\")\n",
    "print(quarter2.flatten())\n",
    "\n",
    "print(\"\\nQuarter 3 Indices:\")\n",
    "print(quarter3.flatten())\n",
    "\n",
    "print(\"\\nQuarter 4 Indices:\")\n",
    "print(quarter4.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter1[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_arrays(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    array_size = 1000000  # Size of the arrays\n",
    "    a = np.random.rand(array_size).astype(np.float32)\n",
    "    b = np.random.rand(array_size).astype(np.float32)\n",
    "\n",
    "    result = add_arrays(a, b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jaxlib\n",
      "  Obtaining dependency information for jaxlib from https://files.pythonhosted.org/packages/62/a1/beb609f27603cf2ce6f3fb14ad2e93bde9324158f872e46509d52b178cdc/jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/selfetni/.local/lib/python3.10/site-packages (from jaxlib) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/selfetni/.local/lib/python3.10/site-packages (from jaxlib) (1.24.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/selfetni/.local/lib/python3.10/site-packages (from jaxlib) (0.2.0)\n",
      "Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jaxlib\n",
      "Successfully installed jaxlib-0.4.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /home/selfetni/.local/lib/python3.10/site-packages (0.0.post9)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.13.0\n",
      "\n",
      "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "Pandas 1.5.3\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "#import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "#print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "#print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 11:58:37.332466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 11:58:37.332846: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Specify the GPU device you want to use (e.g., GPU 0)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python_version>\"3.7\" (from tensorflow-gpu)\n",
      "  Using cached python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-o37jxhf2/tensorflow-gpu_6ca9aafd077e4d71b8c068f4c7ced540/setup.py\", line 37, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(TF_REMOVAL_WARNING)\n",
      "  \u001b[31m   \u001b[0m Exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m The \"tensorflow-gpu\" package has been removed!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Please install \"tensorflow\" instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Other than the name, the two packages have been identical\n",
      "  \u001b[31m   \u001b[0m since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  \u001b[31m   \u001b[0m information, see: pypi.org/project/tensorflow-gpu\n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tensorflow-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "\u001b[31mERROR: Could not build wheels for tensorflow-gpu, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sample_data:\n",
      "[[0.5 0.7]\n",
      " [0.3 0.8]\n",
      " [0.1 0.9]]\n",
      "Updated sample_data:\n",
      "[[0.5        0.7        0.27085461]\n",
      " [0.3        0.8        0.77456136]\n",
      " [0.1        0.9        0.55678509]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the range for random values\n",
    "t_min = 0.0\n",
    "t_max = 1.0\n",
    "\n",
    "# Create a sample data array with two columns\n",
    "sample_data = np.array([[0.5, 0.7],\n",
    "                        [0.3, 0.8],\n",
    "                        [0.1, 0.9]])\n",
    "\n",
    "# Check the initial data\n",
    "print(\"Initial sample_data:\")\n",
    "print(sample_data)\n",
    "\n",
    "# Generate and assign a new column of random values within the specified range\n",
    "new_column = np.random.uniform(t_min, t_max, sample_data.shape[0])\n",
    "sample_data = np.column_stack((sample_data, new_column))\n",
    "\n",
    "# Check the updated data with the new column\n",
    "print(\"Updated sample_data:\")\n",
    "print(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27085461, 0.77456136, 0.55678509])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
